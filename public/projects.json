{
    "projects": [
      {
        "title": "Raytracer",
        "tagline": "A raytracer built in C++, with Phong illumination, shadow mapping, and recursive reflections.",
        "description": "My Raytracer calculates intersections and object normals by creating an object of the Intersection class associated with a given pixel's P and d values in object space. The main function of this object, calculateIntersection(), uses a switch statement to call intersection calculation functions based on the primitive type. These functions themselves have helper functions, which calculate possible T values for each face. The cylinder intersection function, for example, calls a function for intersection with a cylindrical surface, along with two calls to flat base intersection function (at 2 different Y levels). This allows me to reuse code for certain faces across multiple primitives. Once each faces' T values have been calculated, the primitive intersection function picks the smallest positive T value, if any, and returns. Separating my implicit equations by face also allows me to keep track of which face was hit by the ray, which I allows me to quickly calculate object normals. Because of this, my calculateObjectNormal() function follows a similar philosophy of face-based helper functions. While looping through the primitives in my scene, I keep track of the shape with the closest T value. I save this shape's intersection object in closestI and primitive object in closestShape. These are both used to calculate lighting. After looping through, I calculate the object's normal in world space using the inverse transpose of the shape's CTM, as discussed in lecture. I calculate the direction to the camera using's the object's and the camera's positions in world space. I pass all the necessary data to a phong() function in a separate light.cpp class. My current version only implements directional light. I loop through all lights, check if any are directional, and implement phong illumination as explained previously.",
        "thumbnail": "https://raw.githubusercontent.com/BrownCSCI1230/scenefiles/main/illuminate/required_outputs/shadow/shadow_test.png",
        "cover": "https://raw.githubusercontent.com/BrownCSCI1230/scenefiles/main/illuminate/required_outputs/shadow/shadow_test.png",
        "addl": ["https://raw.githubusercontent.com/BrownCSCI1230/scenefiles/main/illuminate/required_outputs/spot_light/spot_light_2.png",
           "https://raw.githubusercontent.com/BrownCSCI1230/scenefiles/main/illuminate/required_outputs/reflection/reflections_complex.png"],
        "link": "https://github.com/lukegriley/Raytracer"
      },
      {
        "title": "QuakeClone",
        "tagline": "Multiplayer FPS (kind of Quake-y) coded entirely in C++ and GLSL, in collaboration with Evan M., Matthew M., and Jakob W.",
        "description": "Quake Clone\nIntroduction: What were your overall project goals? What (briefly) did you achieve?\nThe overall goal of this project was to design and make a multiplayer FPS game. This would\nprovide challenges for synchronizing physics and game state across many clients. We ended up\nachieving a playable multiplayer deathmatch game.\n● Design/Implementation: What did you build, and how does it work? For this part, give\nan overview of the major components of your system design and how they work, similar\nto what you might write in a readme.\nThe project's core was the “Entity Component System,” or “ECS” for short. This design enabled\nus to synchronize game state across different clients more easily than other game architectures.\nAs an overview, the ECS consists of entities (32 bit integers with each bit corresponding to a\ncomponent), components (structs of data associated with different entities), and systems\n(functions that apply to all entities with given components).\nAs a user of our ECS, you register components and systems beforehand. Those get stored in\ncontinuous arrays where the index into the array is the entity’s id. Another continuous array is\nstored that maps entity ids to their corresponding component flags. Then, you register “systems”\nwhich are functions that have the ecs, entity, and delta time as parameters along with a bitmask\nof required components.\nOnce registered, each system is called on all entities with corresponding bitmasks every frame.\nWe opted to use arrays in the backend because we had 1 byte corresponding to each component's\nID, meaning there would be 256 elements for each component. While there could be\noptimizations here to make this expandable, having it fixed means we get ease of use from the\nnetwork side, and other efficiencies (such as cache hits). It also reduced the complexity of our\ncode, and given this project's scope was large between needing both graphics and networking\ncapabilities, that was helpful. In addition, the scale of our project is pretty small (only a handful\nof players shooting no more than ~5 projectiles at a time), and thus it was extremely unlikely we\nwould need more than 256 entities at a time.\nTo prevent jitter and allow for similar designs between the server and clients, we have a system\nof “authority.” A client will have authority over anything it creates, and the server initially sends\nthe corresponding player to kick it off. The server has authority over everything else. Any\nnetwork client with authority over an object has authority over all of the client's state; incoming\npackets won’t override their version of its state, and they will send out packets with entities they\nhave authority over.\nOne issue with this is that there needs to be more local security. An attacker could modify the\nclient to position their player or projectiles anywhere on the map without checks. On the other\nhand, it also ensures that malicious actors cannot edit clients.\nBecause ECS is a data-driven system, designing the actual networking was relatively\nstraightforward. No TCP was used, only UDP sockets. The server starts up, a connection is\nestablished using UDP and getting IP information from the sockets, then every game tick the\nstate is broadcasted.\nTo broadcast state, the server (or client with all entities it has authority over) iterates through all\nthe data in the ECS and puts any alive and registered entities and data onto UDP packets, and\nsends them off. Because state updates are sent so frequently and because speed is of the essence,\nreliability and packet order are not necessary. However, each packet header has information\nabout what local tick it was sent on, which is then used to compare with the last received packets\nto know what or what not to deserialize. The data is serialized by registering object, flag, then the\ncomponent data, and deserialized by copying component data based on the inputted object and\nflags (component order is the same order as on the flags), and “null-terminated” when the next\nobject and flags are both 0.\nTo ensure synchronization, the client and server register the same systems and components\n(except the render system because that is only client-sided). They are running identical systems\nand constantly synchronizing their data, so everything should be relatively in sync.\nAll in all, the process goes something like this:\n- The server starts up\n- A client sends a request to the server on a pre-agreed-upon port and IP\n- The server gets this request, creates a “connection” struct representing that client, and\nsends back a welcome message with the player entity corresponding with the client\n- The client receives the welcome message gets its player entity, and also sets up a\nconnection struct representing the server\n- The game loop begins\n- At the beginning of each frame, the server and client check a queue of game state\nupdates.\n- If this queue is not empty, copy its data onto the local version of the ECS for all\nobjects that they do not have authority over\n- For the first set of packets received, authority doesn’t matter. They will\njust receive the state from the server.\n- Run and render the simulation (physics, rendering, etc.)\n- Any objects created by objects this client or server has authority over will also\nhave authority by the local client\n- Broadcast the game state\n- For the client, broadcast all objects they have authority over to the server\n- For the server, broadcast the whole game state to all clients (when deserialized, if\nthey have authority, it will be ignored)\n● Discussion/Results: Describe any results you have, what you have learned, and any\nchallenges you faced along the way. For this part, please include any relevant\nlogs/screenshots of your program operating (and/or reference your demo video).\nIt took a while for us to get the server working consistently. We also had to do a lot of wrangling\nand meetups to align the graphics and server teams. Debugging was much easier as we had new\ntools and could visualize issues. Most of the progress was slow-moving until the very end, where\nmuch of the game logic came together in the last day or two.\n● Conclusions/Future work: Overall, what have you learned? How did you feel about this\nproject overall? If you could keep working on this project, what would you do next?\nWe felt that the unique nature of this project being split across two very different classes offered\none of the most interesting takes on not only how network programming is actually used in the\ncontext of a real “product” but also how to balance trade-offs between both camps to ensure that\nnetworking is smooth and reliable with minimal compromise to graphics quality or game\nfeatures. Although ECS was extremely well-suited to help us find this balance, the need to\ncommunicate between graphics programmers and network designers could still cause a bit of\nfriction, given that only one person in the group was in both classes and had to act as a liaison\nbetween the two graphics/rendering-centered team members and the other student in networks.\nThe next significant thing we want to do on this project is graphics interpolation. Right now,\nbecause the entire state is synched up and the same transform data used for components is used\nfor physics, there is a lot of jitter for the graphics from other players. To solve this problem, we\nwould need a system to interpolate the graphics' transformation based on physics data obtained\nfrom previous ticks to render the graphics more smoothly.\nRetransmission. Our design approach was incredibly nice because many seemingly hard\nsynchronization problems were solved for us. How do you combat jitter? Give clients control\nover their player and its data. How about projectiles getting destroyed? All the clients are\nrunning the same simulation, so having projectiles destroyed on a timer or hitting a wall will sort\nitself out. One problem we faced, though, is that once objects are destroyed locally, their data\nwill no longer be broadcast. You could broadcast that they have died by sending empty flags, but\nit could get dropped if you only do it for one packet, and doing it repeatedly forever is wasteful.\nIf an in-between, how many to send? Having retransmission and acknowledgment to create an\nimplementation of “reliable” (but unordered) UDP (or even interspersing TCP packets) to\nreliably send over things that either won’t be sorted out by the simulation or are controlled\nrandomly (such as by player commands) is a clear next step.\nA better solution to prevent jitter and control than the current authority system. Ideally, the server\nshould authenticate the state it receives from clients. If it strays too much from the servers or in\nan unusual way, that player can be kicked or banned.\nGithub Repository: https://github.com/evan-mick/quake-clone\nDemo Video: https://drive.google.com/file/d/1oyknDe_eDyTXVMn1sffx-3-eQqQfbj4V/view?usp=sharing",
        "thumbnail": "https://private-user-images.githubusercontent.com/70218073/293491966-ec65f697-8ecc-4a7e-8d2e-786e16e6f55c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDQwMDIxMDYsIm5iZiI6MTcwNDAwMTgwNiwicGF0aCI6Ii83MDIxODA3My8yOTM0OTE5NjYtZWM2NWY2OTctOGVjYy00YTdlLThkMmUtNzg2ZTE2ZTZmNTVjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyMzEyMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjMxVDA1NTAwNlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWJkN2E4MTRlMjIzMmEyNDU1NDZlMTdjYTllMWI2NTdkZDZhNTZlMWQyMTk0YjBlYmIwNGVkZTNmNzBkZWQzNGImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.F_QNpahlwJJamedH8Ia7DJRsWYG5Eed6sUHKmWvgang",
        "cover": "https://private-user-images.githubusercontent.com/70218073/293491966-ec65f697-8ecc-4a7e-8d2e-786e16e6f55c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDQwMDIxMDYsIm5iZiI6MTcwNDAwMTgwNiwicGF0aCI6Ii83MDIxODA3My8yOTM0OTE5NjYtZWM2NWY2OTctOGVjYy00YTdlLThkMmUtNzg2ZTE2ZTZmNTVjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyMzEyMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjMxVDA1NTAwNlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWJkN2E4MTRlMjIzMmEyNDU1NDZlMTdjYTllMWI2NTdkZDZhNTZlMWQyMTk0YjBlYmIwNGVkZTNmNzBkZWQzNGImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.F_QNpahlwJJamedH8Ia7DJRsWYG5Eed6sUHKmWvgang",
        "addl": ["https://private-user-images.githubusercontent.com/70218073/293491969-9c2ca7f9-9616-4ea2-bfd5-5f4efcaacdec.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDQwMDIxMDYsIm5iZiI6MTcwNDAwMTgwNiwicGF0aCI6Ii83MDIxODA3My8yOTM0OTE5NjktOWMyY2E3ZjktOTYxNi00ZWEyLWJmZDUtNWY0ZWZjYWFjZGVjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyMzEyMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjMxVDA1NTAwNlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA5N2NkZjBkNjYzZGI3ZmJiMmFjNjgzNDM2ODgwYzM3N2Q2NWQ1NmVjNzgwN2NlYjJiYmRkYjZiN2E5ZmYxMDQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ZbqrnUob0v2IET3Hn36s_Aiskfz_-ppEGQbnN-qBYGg"],
        "link": "https://drive.google.com/file/d/1oyknDe_eDyTXVMn1sffx-3-eQqQfbj4V/view"
      },
      {
        "title": "Flipbook",
        "tagline": "Accessible full-stack animation web app.",
        "description":"Flipbook\n\nA full-stack animation webapp made with Typescript, React, MongoDB, in collaboration with aong9, oanders6, dsaunde2, bmaizes.\n\n## Background\nMaking animations has an accessibility problem. To make quality animations this requires professional software which is often bricked by a steep learning curve, expensive paywalls, and hardware demands. We gathered knowledge about this problem through interviews with peer animators, non-animators with interest in doing so, and through reviews of other animation software.\n\nOur project solves this by bridging the accessibility gap in animation with a simple sketch and tracing based interface. Of course, a non-software based solution would be to produce physical flipbooks to be drawn on, but our software allows the fast creation of animation cells and tracing of existing images/video frames. Doing this on a physical flipbook would require a large of paper resources and a backlit tracing surface.\n\nThis app should be a seamless, easy to access application for any users. It should be quickly deployable and with little barrier. The idea is that users will use it whenever they seek to animate something or want to work on an animation project or as a reference to other development projects.\n\n## Structure\n\nWhiteboard data module (model) → stores the data from user input to the website, ex. a series of drawn frames, by calling on the animation module via API\n\nWhiteboard visual module (view) → visually displays the data from the whiteboard data by calling on the animation module via API. This model will be made accessible through ARIA labels and descriptions, and with keyboard shortcuts like enter = move to the next frame, shift + enter = go to previous frame, shift+tab = hide/show the outline from the previous frame\n\nAnimation module (controller) → stores data from all the frames, putting the relevant frame onto the screen when appropriate and allowing new data to be added. Communicates with both the whiteboard visual and whiteboard data modules.\n\nExport module (model) → converts the data for a selected animations into either a GIF or mp4 based on the user’s choice.",
        "thumbnail": "https://private-user-images.githubusercontent.com/70218073/293492840-653ee86a-af59-4d3e-b385-900685e1349c.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDQwMDQwMzMsIm5iZiI6MTcwNDAwMzczMywicGF0aCI6Ii83MDIxODA3My8yOTM0OTI4NDAtNjUzZWU4NmEtYWY1OS00ZDNlLWIzODUtOTAwNjg1ZTEzNDljLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyMzEyMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjMxVDA2MjIxM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVmMThlZjUxNDk3YzE0MjlhNzI4YWZjMzEzNmQxOGEzMWRlZWIwY2E3NjQ5ZDU4NTgyMmIxZDQyNjcyMDUyNmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ajblCoZkmg041QjBDuh-UD9OIALSoob1Jl9wK-4h3_g",
        "cover": "https://private-user-images.githubusercontent.com/70218073/293492840-653ee86a-af59-4d3e-b385-900685e1349c.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDQwMDQwMzMsIm5iZiI6MTcwNDAwMzczMywicGF0aCI6Ii83MDIxODA3My8yOTM0OTI4NDAtNjUzZWU4NmEtYWY1OS00ZDNlLWIzODUtOTAwNjg1ZTEzNDljLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyMzEyMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjMxVDA2MjIxM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVmMThlZjUxNDk3YzE0MjlhNzI4YWZjMzEzNmQxOGEzMWRlZWIwY2E3NjQ5ZDU4NTgyMmIxZDQyNjcyMDUyNmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ajblCoZkmg041QjBDuh-UD9OIALSoob1Jl9wK-4h3_g",
        "addl": ["https://private-user-images.githubusercontent.com/70218073/293492843-4c40fc5b-38fe-4613-ae68-2efc703047eb.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDQwMDQwMzMsIm5iZiI6MTcwNDAwMzczMywicGF0aCI6Ii83MDIxODA3My8yOTM0OTI4NDMtNGM0MGZjNWItMzhmZS00NjEzLWFlNjgtMmVmYzcwMzA0N2ViLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyMzEyMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjMxVDA2MjIxM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTlkNDFjMTE4YTk5NjMyNzgyODYwNDVmNWM4YTAyY2IxNmI1MzIwMWQwYWRiY2U3ZjUxOTFlOTQ3NjhjYTViMWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.5qOsHSfSXQijU9JSdE8Yksh-yWo0ZQsyVEAI6rD2ukQ"],
        "link": "https://github.com/lukegriley/Flipbook"
      },
      {
        "title": "Rasterization",
        "tagline": "Real-time graphics pipeline template made with C++ and GLSL.",
        "description":"In this project, I continued building upon the foundation established in the CS1230's Raytracing assignments. The project involved designing a real-time scene viewer using components from previous labs, including Parsing, Transformations, Trimeshes, VAOs, and Shaders. The scene parser from Lab 5: Parsing was utilized to read in scene files in JSON format, replacing the previous use of .ini files. Additionally, I implemented tessellation for shapes such as cube, sphere, cone, and cylinder, extending the capabilities developed in Lab 8: Trimeshes.\n\nThe camera functionality was enhanced to generate both view and projection matrices based on the scene file's camera parameters. Unlike the raytracer, the real-time viewer required a projection matrix to convert from camera space to clip space for OpenGL rendering. This introduced the ability to interactively adjust the near and far clipping planes in real-time.\n\nThe core of the project focused on data handling, leveraging OpenGL pipelines to manipulate and manage scene data. VAOs and VBOs were appropriately designed to represent shape data in OpenGL, minimizing code duplication and ensuring an object-oriented approach. Shaders were extended to support directional lights, ambient, diffuse, and specular intensity computation, and the final color computation integrating object and light colors. The shaders were designed to handle up to 8 simultaneous lights using arrays and structs in GLSL.\n\nThe project was structured to maintain efficiency and stability, avoiding excess memory usage by carefully managing VBOs and VAOs. The finish() function was implemented to clean up generated memory before program exit. The Realtime::settingsChanged() function was crucial for handling changes in parameters such as near and far clipping planes and shape tessellation parameters.\n\nThe results showcased the real-time renderer's capabilities through sample images, demonstrating the rendering of complex scenes with varying levels of tessellation and lighting effects. The Scenes Viewer web tool facilitated the creation and modification of scene files, streamlining the development process.\n\nFor the submission, the repository included a submission template file (submission-lights-camera.md) containing details about design choices, collaboration, known bugs, and implemented extra credit. The project was graded based on camera data, shape implementations, shaders, and software engineering efficiency and stability, with extra credit options available for further enhancements.",
        "thumbnail": "https://raw.githubusercontent.com/BrownCSCI1230/scenefiles/main/action/required_outputs/recursive_sphere_4_sharpen.png",
        "cover": "https://raw.githubusercontent.com/BrownCSCI1230/scenefiles/main/action/required_outputs/primitive_salad_1_invert.png",
        "addl": ["https://raw.githubusercontent.com/BrownCSCI1230/scenefiles/main/action/required_outputs/recursive_sphere_4_sharpen.png",
          "https://raw.githubusercontent.com/BrownCSCI1230/scenefiles/main/action/required_outputs/spot_light_2.png"],
        "link": "https://github.com/lukegriley/rasterizer"
      },
      {
        "title": "Decision Tree",
        "tagline": "Real-time graphics pipeline template made with C++ and GLSL.",
        "description":"Flipbook\n\nA full-stack animation webapp made with Typescript, React, MongoDB, in collaboration with aong9, oanders6, dsaunde2, bmaizes.\n\n## Background\nMaking animations has an accessibility problem. To make quality animations this requires professional software which is often bricked by a steep learning curve, expensive paywalls, and hardware demands. We gathered knowledge about this problem through interviews with peer animators, non-animators with interest in doing so, and through reviews of other animation software.\n\nOur project solves this by bridging the accessibility gap in animation with a simple sketch and tracing based interface. Of course, a non-software based solution would be to produce physical flipbooks to be drawn on, but our software allows the fast creation of animation cells and tracing of existing images/video frames. Doing this on a physical flipbook would require a large of paper resources and a backlit tracing surface.\n\nThis app should be a seamless, easy to access application for any users. It should be quickly deployable and with little barrier. The idea is that users will use it whenever they seek to animate something or want to work on an animation project or as a reference to other development projects.\n\n## Structure\n\nWhiteboard data module (model) → stores the data from user input to the website, ex. a series of drawn frames, by calling on the animation module via API\n\nWhiteboard visual module (view) → visually displays the data from the whiteboard data by calling on the animation module via API. This model will be made accessible through ARIA labels and descriptions, and with keyboard shortcuts like enter = move to the next frame, shift + enter = go to previous frame, shift+tab = hide/show the outline from the previous frame\n\nAnimation module (controller) → stores data from all the frames, putting the relevant frame onto the screen when appropriate and allowing new data to be added. Communicates with both the whiteboard visual and whiteboard data modules.\n\nExport module (model) → converts the data for a selected animations into either a GIF or mp4 based on the user’s choice.",
        "thumbnail": "https://private-user-images.githubusercontent.com/70218073/293492840-653ee86a-af59-4d3e-b385-900685e1349c.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDQwMDQwMzMsIm5iZiI6MTcwNDAwMzczMywicGF0aCI6Ii83MDIxODA3My8yOTM0OTI4NDAtNjUzZWU4NmEtYWY1OS00ZDNlLWIzODUtOTAwNjg1ZTEzNDljLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyMzEyMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjMxVDA2MjIxM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVmMThlZjUxNDk3YzE0MjlhNzI4YWZjMzEzNmQxOGEzMWRlZWIwY2E3NjQ5ZDU4NTgyMmIxZDQyNjcyMDUyNmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ajblCoZkmg041QjBDuh-UD9OIALSoob1Jl9wK-4h3_g",
        "cover": "https://private-user-images.githubusercontent.com/70218073/293492840-653ee86a-af59-4d3e-b385-900685e1349c.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDQwMDQwMzMsIm5iZiI6MTcwNDAwMzczMywicGF0aCI6Ii83MDIxODA3My8yOTM0OTI4NDAtNjUzZWU4NmEtYWY1OS00ZDNlLWIzODUtOTAwNjg1ZTEzNDljLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyMzEyMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjMxVDA2MjIxM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVmMThlZjUxNDk3YzE0MjlhNzI4YWZjMzEzNmQxOGEzMWRlZWIwY2E3NjQ5ZDU4NTgyMmIxZDQyNjcyMDUyNmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ajblCoZkmg041QjBDuh-UD9OIALSoob1Jl9wK-4h3_g",
        "addl": ["https://private-user-images.githubusercontent.com/70218073/293492843-4c40fc5b-38fe-4613-ae68-2efc703047eb.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDQwMDQwMzMsIm5iZiI6MTcwNDAwMzczMywicGF0aCI6Ii83MDIxODA3My8yOTM0OTI4NDMtNGM0MGZjNWItMzhmZS00NjEzLWFlNjgtMmVmYzcwMzA0N2ViLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyMzEyMzElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjMxVDA2MjIxM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTlkNDFjMTE4YTk5NjMyNzgyODYwNDVmNWM4YTAyY2IxNmI1MzIwMWQwYWRiY2U3ZjUxOTFlOTQ3NjhjYTViMWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.5qOsHSfSXQijU9JSdE8Yksh-yWo0ZQsyVEAI6rD2ukQ"],
        "link": "https://github.com/lukegriley/Flipbook"
      }
    ]
  }
  